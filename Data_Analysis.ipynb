{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7c0a02",
   "metadata": {},
   "source": [
    "# Python Cheatsheets - DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b011c",
   "metadata": {},
   "source": [
    "## Data Manipulation\n",
    "\n",
    "### Pandas\n",
    "Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n",
    "built on top of the Python programming language. It is built on numpy and matplotlib libraries. It provides high-performance, easy-to-use data structures and data analysis tools for Python. \n",
    "\n",
    "More information: https://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6352ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN IF PANDAS IS NOT INSTALLED\n",
    "\n",
    "# install pandas either with conda or with pip\n",
    "# conda install -c conda-forge pandas\n",
    "%pip install pandas\n",
    "%pip install numerize\n",
    "\n",
    "# verify if it is installed\n",
    "# pip show pandas\n",
    "# pip show numerize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0adb20cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries for pandas and other necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from numerize.numerize import numerize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069ac4a",
   "metadata": {},
   "source": [
    "#### 1) Data Classes\n",
    "\n",
    "Pandas has two types of classes to handle data: __Series__ and __DataFrame__\n",
    "\n",
    "- __Series:__ A one-dimensional labeled array holding data of any type such as integers, strings, Python objects etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba3a1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:  <class 'pandas.core.series.Series'>\n",
      "0    1.0\n",
      "1    3.0\n",
      "2    4.0\n",
      "3    NaN\n",
      "4    6.0\n",
      "5    9.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create a series by passing a list of values\n",
    "s = pd.Series([1, 3, 4, np.nan, 6, 9])\n",
    "print(\"Type: \",type(s), end=\"\\n\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedea56b",
   "metadata": {},
   "source": [
    "- __DataFrame:__ A two-dimensional data structure that holds data like a two-dimension array or a table with rows and columns.\n",
    "\n",
    "_DataFrame from a dictionary:_ A DataFrame can be created by passing a _dictionary_ of objects where the keys are the column labels and the values are the column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0e9c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:  <class 'pandas.core.frame.DataFrame'>\n",
      "           Country    Capital  Population\n",
      "DE         Germany     Berlin    84552242\n",
      "AU       Australia   Canberra    26713205\n",
      "JP           Japan      Tokyo   123753041\n",
      "IN           India  New Delhi  1450935791\n",
      "CN           China    Beijing  1419321278\n",
      "GB  United Kingdom     London    69138192\n"
     ]
    }
   ],
   "source": [
    "# create a DataFrame with a dictionary\n",
    "names = ['Germany', 'Australia', 'Japan', 'India', 'China', 'United Kingdom']\n",
    "cap =  ['Berlin', 'Canberra', 'Tokyo', 'New Delhi', 'Beijing', 'London']\n",
    "pop = [84552242, 26713205, 123753041, 1450935791, 1419321278, 69138192]\n",
    "codes = ['DE', 'AU', 'JP', 'IN', 'CN', 'GB']\n",
    "\n",
    "# create dictionary my_dict with three key:value pairs: my_dict\n",
    "my_dict = {\n",
    "    'Country':names,\n",
    "    'Capital':cap,\n",
    "    'Population':pop\n",
    "}\n",
    "\n",
    "# build a DataFrame countries from my_dict: countries\n",
    "countries = pd.DataFrame(my_dict)\n",
    "countries.index = codes\n",
    "\n",
    "# save the data as a csv file for the latter exercises\n",
    "countries.to_csv(\"data/countries.csv\")\n",
    "\n",
    "# print DataFrame\n",
    "print(\"Type: \",type(countries), end=\"\\n\")\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017d732",
   "metadata": {},
   "source": [
    "_DataFrame from a source file:_ Putting data in a dictionary and then building a DataFrame is not very efficient while dealing with millions of observations. A DataFrame can also be created by reading data from a _source file_ where the data is typically available with a regular structure. An example is the CSV file, which is short for \"comma-separated values\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe14b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Country    Capital  Population\n",
      "DE         Germany     Berlin    84552242\n",
      "AU       Australia   Canberra    26713205\n",
      "JP           Japan      Tokyo   123753041\n",
      "IN           India  New Delhi  1450935791\n",
      "CN           China    Beijing  1419321278\n",
      "GB  United Kingdom     London    69138192\n"
     ]
    }
   ],
   "source": [
    "# read the csv file (data extraxted from https://www.kaggle.com/datasets/lashagoch/life-expectancy-who-updated)\n",
    "countries = pd.read_csv('data/countries.csv', index_col=0)\n",
    "\n",
    "# print out the data\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aec7d4",
   "metadata": {},
   "source": [
    "#### 2) Exploring Data\n",
    "\n",
    "Pandas has several methods to explore a data and get a sense of its contents. \n",
    "\n",
    "__Methods:__\n",
    "- __head():__ It returns the first few rows of the DataFrame\n",
    "- __info():__ It displays the names of the columns, the data types they contain, and whether they have any missing values\n",
    "- __describe():__ It computes some summary statistics for numerical columns\n",
    "\n",
    "__Attributes:__\n",
    "- __shape:__ It contains a tuple that holds the number of rows followed by the number of columns\n",
    "- __values:__ It contains the data values in a 2D NumPy array\n",
    "- __columns:__ It contains the column names\n",
    "- __index:__ It contains row numbers or row names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a70e49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6, 3)\n",
      "Index: Index(['DE', 'AU', 'JP', 'IN', 'CN', 'GB'], dtype='object')\n",
      "Columns: Index(['Country', 'Capital', 'Population'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6 entries, DE to GB\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Country     6 non-null      object\n",
      " 1   Capital     6 non-null      object\n",
      " 2   Population  6 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 364.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# read the countries data\n",
    "#countries = pd.read_csv('data/countries.csv', index_col = 0)\n",
    "\n",
    "# check the shape of the DataFrame\n",
    "print(\"Shape:\", countries.shape)\n",
    "\n",
    "# check the index and columns of the DataFrame\n",
    "print(\"Index:\", countries.index)\n",
    "print(\"Columns:\", countries.columns)\n",
    "\n",
    "# explore the countries data with info\n",
    "print(countries.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec404e95",
   "metadata": {},
   "source": [
    "#### 3) Indexing and Selecting Data\n",
    "\n",
    "- __Square Brackets:__ The simplest, but not the most powerful way, to index and select is to use square brackets.\n",
    "\n",
    "    - Single square brackets ([]) return a Pandas Series.\n",
    "    - Double square brackets ([[]]) return a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1997382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country column as a Pandas Series:\n",
      "DE           Germany\n",
      "AU         Australia\n",
      "JP             Japan\n",
      "IN             India\n",
      "CN             China\n",
      "GB    United Kingdom\n",
      "Name: Country, dtype: object\n",
      "\n",
      "Country and Population columns as a Pandas DataFrame:\n",
      "           Country  Population\n",
      "DE         Germany    84552242\n",
      "AU       Australia    26713205\n",
      "JP           Japan   123753041\n",
      "IN           India  1450935791\n",
      "CN           China  1419321278\n",
      "GB  United Kingdom    69138192\n"
     ]
    }
   ],
   "source": [
    "# read the countries data\n",
    "#countries = pd.read_csv('data/countries.csv', index_col = 0)\n",
    "\n",
    "# print out country column as Pandas Series\n",
    "print(\"Country column as a Pandas Series:\")\n",
    "print(countries['Country']) \n",
    "\n",
    "# print out country and population columns as Pandas DataFrame\n",
    "print(\"\\nCountry and Population columns as a Pandas DataFrame:\") \n",
    "print(countries[['Country', 'Population']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811c96f2",
   "metadata": {},
   "source": [
    "- __Selecting Rows with Slicing:__ Use slices to select specific rows or observations. We can only select rows using square brackets if we specify a slice, like 0:4, using the integer indexes of the rows and not the row labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be4e3856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country   Capital  Population\n",
      "DE    Germany    Berlin    84552242\n",
      "AU  Australia  Canberra    26713205\n",
      "JP      Japan     Tokyo   123753041\n",
      "\n",
      "           Country    Capital  Population\n",
      "IN           India  New Delhi  1450935791\n",
      "CN           China    Beijing  1419321278\n",
      "GB  United Kingdom     London    69138192\n"
     ]
    }
   ],
   "source": [
    "# read the countries data\n",
    "#countries = pd.read_csv('data/countries.csv', index_col = 0)\n",
    "\n",
    "# print out first 3 observations\n",
    "print(countries[:3], end=\"\\n\\n\")\n",
    "\n",
    "# print out fourth, fifth and sixth observation\n",
    "print(countries[3:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38ab4e",
   "metadata": {},
   "source": [
    "- ```loc``` __and__ ```iloc```__:__\n",
    "\n",
    "    - ```loc``` is label-based, using row and column labels.\n",
    "    - ```iloc``` is index-based, using integer positions.\n",
    "\n",
    "Pandas also allows to designate any column as an index. Setting a column as index is done with the ```.set_index()``` method while ```.reset_index()``` is used to reset the index to initial version. Setting the __drop__ parameter __True__ drops the newly set index column from the DataFrame. It is also possible to sort the DataFrame by index using the ```.sort_index()``` method. Setting the __level__ parameter defines the leves to sort by and __ascending__ parameters defines the type of the sorting to be done. The syntax is as below:\n",
    "```python\n",
    "df.set_index(\"col_A\")\n",
    "df.reset_index(drop=True)\n",
    "df.sort_index(level=[\"col_A\", \"col_B\"], ascending=[True, False])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b8f44cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country           Japan\n",
      "Capital           Tokyo\n",
      "Population    123753041\n",
      "Name: JP, dtype: object\n",
      "\n",
      "      Country   Capital  Population\n",
      "CN      China   Beijing  1419321278\n",
      "AU  Australia  Canberra    26713205\n",
      "\n",
      "loc['JP'] results the same as iloc[2]:  True\n",
      "loc[['AU','CN']] results the same as iloc[[1, 4]]:  True\n"
     ]
    }
   ],
   "source": [
    "# read the countries data\n",
    "#countries = pd.read_csv('data/countries.csv', index_col = 0)\n",
    "\n",
    "# print out observation for Japan as Pandas Series\n",
    "print(countries.loc['JP'], end=\"\\n\\n\")\n",
    "\n",
    "# print out observations for Australia and China as Pandas DataFrame\n",
    "print(countries.loc[['AU','CN']].sort_index(level=\"Capital\", ascending=False), end=\"\\n\\n\")\n",
    "\n",
    "# check loc and iloc results the same for Pandas Series\n",
    "print(\"loc['JP'] results the same as iloc[2]: \", countries.loc['JP'].equals(countries.iloc[2]))\n",
    "\n",
    "# check loc and iloc results the same for Pandas DataFrame\n",
    "print(\"loc[['AU','CN']] results the same as iloc[[1, 4]]: \", countries.loc[['AU','CN']].equals(countries.iloc[[1,4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14783a37",
   "metadata": {},
   "source": [
    "- __Combining Rows and Columns:__ Use ```loc``` and ```iloc``` to select specific rows and columns simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "690fb54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population of India:  1450935791\n",
      "\n",
      "DE      84552242\n",
      "AU      26713205\n",
      "JP     123753041\n",
      "IN    1450935791\n",
      "CN    1419321278\n",
      "GB      69138192\n",
      "Name: Population, dtype: int64\n",
      "\n",
      "   Capital\n",
      "DE  Berlin\n",
      "\n",
      "           Country  Population\n",
      "IN           India  1450935791\n",
      "GB  United Kingdom    69138192\n",
      "\n",
      "loc['IN', 'Population'] results the same as iloc[3, 2]:  True\n",
      "loc[:,'Population'] results the same as iloc[:, 2]:  True\n",
      "loc[['IN','GB'],['Country','Population']] results the same as iloc[[3, 5], [0, 2]]:  True\n"
     ]
    }
   ],
   "source": [
    "# read the countries data\n",
    "#countries = pd.read_csv('data/countries.csv', index_col = 0)\n",
    "\n",
    "# print out Population value of India\n",
    "print(\"Population of India: \", countries.loc['IN', 'Population'], end=\"\\n\\n\")\n",
    "\n",
    "# print out Population column as Pandas Series\n",
    "print(countries.loc[:,'Population'], end=\"\\n\\n\")\n",
    "\n",
    "# print out Capital value of Germany as Pandas DataFrame\n",
    "print(countries.loc[['DE'],['Capital']], end=\"\\n\\n\")\n",
    "\n",
    "# print sub-DataFrame as Pandas DataFrame\n",
    "print(countries.loc[['IN','GB'],['Country','Population']], end=\"\\n\\n\")\n",
    "\n",
    "# check loc and iloc results the same\n",
    "print(\"loc['IN', 'Population'] results the same as iloc[3, 2]: \", countries.loc['IN', 'Population'] == countries.iloc[3, 2])\n",
    "\n",
    "# check loc and iloc results the same for Pandas Series\n",
    "print(\"loc[:,'Population'] results the same as iloc[:, 2]: \", countries.loc[:,'Population'].equals(countries.iloc[:, 2]))\n",
    "\n",
    "# check loc and iloc results the same for Pandas DataFrame\n",
    "print(\"loc[['IN','GB'],['Country','Population']] results the same as iloc[[3, 5], [0, 2]]: \", \n",
    "      countries.loc[['IN','GB'],['Country','Population']].equals(countries.iloc[[3, 5], [0, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a720634",
   "metadata": {},
   "source": [
    "#### 4) Sorting and Filtering Data\n",
    "\n",
    "Exploring and understanding data in a DataFrame is often easier with ordered rows. It is possible to sort the rows by passing a column name to ```.sort_values()```. To sort by multiple columns, a list of column names is passed to the function call.\n",
    "\n",
    "```python\n",
    "df.sort_values(\"column_1\")                                             # sorting by one column\n",
    "df.sort_values([\"column_1\", \"column_2\"])                               # sorting by multiple columns\n",
    "df.sort_values(\"column_1\", ascending = False)                          # sorting by one column in descending order\n",
    "df.sort_values([\"column_1\", \"column_2\"], ascending = [True, False])    # sorting by multiple columns in varying orders\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a7b78058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Country    Capital  Population\n",
      "GB  United Kingdom     London    69138192\n",
      "JP           Japan      Tokyo   123753041\n",
      "IN           India  New Delhi  1450935791\n",
      "DE         Germany     Berlin    84552242\n",
      "CN           China    Beijing  1419321278\n"
     ]
    }
   ],
   "source": [
    "# read the countries data\n",
    "#countries = pd.read_csv('data/countries.csv', index_col = 0)\n",
    "\n",
    "# sort countries by country names in descending order\n",
    "countries_sorted = countries.sort_values(\"Country\", ascending = False)\n",
    "\n",
    "# print sorted data\n",
    "print(countries_sorted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6728a15",
   "metadata": {},
   "source": [
    "Comparison operators and NumPy logical operators are useful for filtering Pandas DataFrame by certain criteria. In order to filter, a boolean type of Pandas Series is necessary which can be obtained by using comparison and logical operators over DataFrame columns. To filter for multiple conditions at once, NumPy logical operators, ```np.logical_and()```, ```np.logical_or()``` etc., or \"bitwise\" operators, ```&```, ```|``` etc., are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f972d0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly populated countries are: \n",
      "    Country    Capital  Population\n",
      "IN   India  New Delhi  1450935791\n",
      "CN   China    Beijing  1419321278\n",
      "\n",
      "Middle populated countries are: \n",
      "            Country Capital  Population\n",
      "DE         Germany  Berlin    84552242\n",
      "JP           Japan   Tokyo   123753041\n",
      "GB  United Kingdom  London    69138192\n"
     ]
    }
   ],
   "source": [
    "# read the countries data\n",
    "#countries = pd.read_csv('data/countries.csv', index_col = 0)\n",
    "\n",
    "# subset countries by population with comparison operators\n",
    "highly_pop = countries[countries['Population'] > 1000000000]\n",
    "\n",
    "# subset countries by population with numpy logical operators\n",
    "#middle_pop = countries[np.logical_and(countries['Population'] > 50000000, countries['Population'] < 1000000000)]\n",
    "\n",
    "# subset countries by population with bitwise logical operators\n",
    "middle_pop = countries[\n",
    "    (countries['Population'] > 50000000) & \n",
    "    (countries['Population'] < 1000000000)]\n",
    "\n",
    "# print subset data\n",
    "print(\"Highly populated countries are: \\n\", highly_pop)\n",
    "print(\"\\nMiddle populated countries are: \\n\", middle_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c73fba",
   "metadata": {},
   "source": [
    "Filtering data based on categorical variables often involves using the logical \"or\" operators, ```np.logical_or()``` or ```|```, to select rows from multiple categories. A more feasible and shorter way is to use the ```.isin()``` method, which allows writing one condition instead of separate ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "de7e65ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with selected capitals are: \n",
      "     Country    Capital  Population\n",
      "DE  Germany     Berlin    84552242\n",
      "JP    Japan      Tokyo   123753041\n",
      "IN    India  New Delhi  1450935791\n"
     ]
    }
   ],
   "source": [
    "# define a list of desired capitals\n",
    "capitals = [\"Berlin\", \"Tokyo\", \"New Delhi\"]\n",
    "\n",
    "# filter the countries with isin call\n",
    "c_filtered = countries[countries[\"Capital\"].isin(capitals)]\n",
    "\n",
    "# print subset data\n",
    "print(\"Countries with selected capitals are: \\n\", c_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16386346",
   "metadata": {},
   "source": [
    "#### 5) Iterating Over Data\n",
    "\n",
    "Iterating over a Pandas DataFrame is typically done with the ```.iterrows()``` method. A for loop with ```.iterrows()``` iterates over every observation and on every iteration the row label and contents are available as:\n",
    "\n",
    "```python\n",
    "for lab, row in df.iterrows():\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0889f7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE: Germany\n",
      "AU: Australia\n",
      "JP: Japan\n",
      "IN: India\n",
      "CN: China\n",
      "GB: United Kingdom\n"
     ]
    }
   ],
   "source": [
    "# read the countries data\n",
    "#countries = pd.read_csv('data/countries.csv', index_col = 0)\n",
    "\n",
    "for lab, row in countries.iterrows() :\n",
    "    print(lab + \": \" + row[\"Country\"]) # also row.Country is suitable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238e93e",
   "metadata": {},
   "source": [
    "However, iterating over a DataFrame results in creating a new Pandas Series at each iteration, which is not very efficient!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d70096e",
   "metadata": {},
   "source": [
    "#### 6) Manipulating Data\n",
    "\n",
    "- __Add Column:__ Adding new columns to a DataFrame has many names, such as transforming, mutating, and feature engineering. It is possibe to generate new columns from scratch or by deriving them from existing columns. To add a column to a Pandas DataFrame by calling a function on another column ```.apply()``` call is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6e43768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Country_Upper    Capital        Pop_M Pop_Readable\n",
      "DE         GERMANY     Berlin    84.552242       84.55M\n",
      "AU       AUSTRALIA   Canberra    26.713205       26.71M\n",
      "JP           JAPAN      Tokyo   123.753041      123.75M\n",
      "IN           INDIA  New Delhi  1450.935791        1.45B\n",
      "CN           CHINA    Beijing  1419.321278        1.42B\n",
      "GB  UNITED KINGDOM     London    69.138192       69.14M\n"
     ]
    }
   ],
   "source": [
    "# copy the countries DataFrame to avoid reflecting the changes on the original\n",
    "c_copy = countries.copy()\n",
    "\n",
    "# add a column with population in millions\n",
    "c_copy[\"Pop_M\"] = c_copy[\"Population\"] / 1000000\n",
    "\n",
    "# add a column with capitalized country names\n",
    "c_copy[\"Country_Upper\"] = c_copy[\"Country\"].apply(str.upper)\n",
    "\n",
    "# add a column with population in human readable format\n",
    "c_copy[\"Pop_Readable\"] = c_copy[\"Population\"].apply(numerize)\n",
    "\n",
    "# print the reulting DataFrame with new columns\n",
    "print(c_copy[[\"Country_Upper\", \"Capital\", \"Pop_M\", \"Pop_Readable\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc0c94",
   "metadata": {},
   "source": [
    "#### 7) Aggregating Data\n",
    "\n",
    "- __Summary Statistics:__ Summary statistics, such as mean, median, minimum, maximum, and standard deviation, allows to get a better sense of data. While Pandas and NumPy provide such many functions to summarize the data, the ```.agg()``` method allows applying custom functions as well as applying functions to more than one column of a DataFrame at once, making aggregations very efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a15c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2864 entries, 0 to 2863\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Country                    2864 non-null   object \n",
      " 1   Region                     2864 non-null   object \n",
      " 2   Year                       2864 non-null   int64  \n",
      " 3   Alcohol_consumption        2864 non-null   float64\n",
      " 4   BMI                        2864 non-null   float64\n",
      " 5   GDP_per_capita             2864 non-null   int64  \n",
      " 6   Population_mln             2864 non-null   float64\n",
      " 7   Schooling                  2864 non-null   float64\n",
      " 8   Economy_status_Developed   2864 non-null   int64  \n",
      " 9   Economy_status_Developing  2864 non-null   int64  \n",
      " 10  Life_expectancy            2864 non-null   float64\n",
      "dtypes: float64(5), int64(4), object(2)\n",
      "memory usage: 268.5+ KB\n",
      "None\n",
      "Mean BMI: 25.032925977653633\n",
      "Median BMI: 25.5\n",
      "Max Population (M): 1379.86\n",
      "Min Population (M): 0.08\n",
      "IQR of Population (M): 21.59\n"
     ]
    }
   ],
   "source": [
    "# read the csv file (data extraxted from https://www.kaggle.com/datasets/lashagoch/life-expectancy-who-updated)\n",
    "world = pd.read_csv('data/world_development.csv', index_col=0)\n",
    "\n",
    "# print the info about the World Development DataFrame\n",
    "print(world.info())\n",
    "\n",
    "# print the mean of BMI\n",
    "print(\"Mean BMI:\", world[\"BMI\"].mean())\n",
    "\n",
    "# print the median of BMI\n",
    "print(\"Median BMI:\", world[\"BMI\"].median())\n",
    "\n",
    "# print the maximum population in millions\n",
    "print(\"Max Population (M):\", world[\"Population_mln\"].max())\n",
    "\n",
    "# print the minimum population in millions\n",
    "print(\"Min Population (M):\", world[\"Population_mln\"].min())\n",
    "\n",
    "# define a custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# print IQR of the population in millions\n",
    "print(\"IQR of Population (M):\", world[\"Population_mln\"].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c93ef0",
   "metadata": {},
   "source": [
    "- __Counting and Grouping:__ Removing duplicates is essential to get accurate counts to avoid counting the same thing multiple times. ```.drop_duplicates()``` method allows to drop duplicates with respect to a defined subset. Counting allows to get an overview of data and to spot curiosities that might not be noticed otherwise. ```.value_counts()``` method allows to count numbers with respect to a column with specifying whther they should be normalized and sorted or not. The ```.groupby()``` method, on the other hand, allows to calculate grouped summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bae888a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developing Countries in North America:\n",
      "328    Mexico\n",
      "Name: Country, dtype: object\n",
      "\n",
      "Proportion of Developing Countries in Each Region:\n",
      "Region\n",
      "Africa                           0.359155\n",
      "Asia                             0.183099\n",
      "Central America and Caribbean    0.133803\n",
      "Middle East                      0.091549\n",
      "South America                    0.084507\n",
      "Rest of Europe                   0.077465\n",
      "Oceania                          0.063380\n",
      "North America                    0.007042\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# subset the rows where the economy status is developing and drop duplicate countries\n",
    "developing_countries = world[world[\"Economy_status_Developing\"] == 1].drop_duplicates(subset=\"Country\")\n",
    "\n",
    "# print the developing countries in North America\n",
    "print(\"Developing Countries in North America:\")\n",
    "print(developing_countries[developing_countries[\"Region\"] == \"North America\"][\"Country\"])\n",
    "\n",
    "# get the proportion of developing countries in each region and sort\n",
    "print(\"\\nProportion of Developing Countries in Each Region:\")\n",
    "dev_props_sorted = developing_countries[\"Region\"].value_counts(sort=True, normalize=True)\n",
    "print(dev_props_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb3feb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proportion of Developing Countries Population by Region:\n",
      "Region\n",
      "Africa                           0.170869\n",
      "Asia                             0.631887\n",
      "Central America and Caribbean    0.014046\n",
      "Middle East                      0.049830\n",
      "North America                    0.018397\n",
      "Oceania                          0.001996\n",
      "Rest of Europe                   0.041256\n",
      "South America                    0.071720\n",
      "Name: Population_mln, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# group by region and get the sum of the population\n",
    "gdp_by_region = developing_countries.groupby(\"Region\")[\"Population_mln\"].sum()\n",
    "\n",
    "# get proportion for each region\n",
    "print(\"\\nProportion of Developing Countries Population by Region:\")\n",
    "print(gdp_by_region / sum(gdp_by_region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c21e14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schooling (avg years that people aged 25+ spent in formal education) Stats of Developing Countries by Region:\n",
      "                               min   max       mean  median\n",
      "Region                                                     \n",
      "Africa                         1.3   9.0   4.588235    4.00\n",
      "Asia                           2.2  11.7   7.100000    7.40\n",
      "Central America and Caribbean  4.3  11.0   7.836842    7.90\n",
      "Middle East                    2.8   9.6   7.761538    8.60\n",
      "North America                  7.0   7.0   7.000000    7.00\n",
      "Oceania                        4.3  10.3   6.811111    6.50\n",
      "Rest of Europe                 7.2  12.6  10.554545   10.80\n",
      "South America                  6.5  10.1   8.150000    8.05\n"
     ]
    }
   ],
   "source": [
    "# for each region in developing countries, aggregate schooling: get min, max, mean, and median\n",
    "print(\"\\nSchooling (avg years that people aged 25+ spent in formal education) Stats of Developing Countries by Region:\")\n",
    "schooling_stats = developing_countries.groupby(\"Region\")[\"Schooling\"].agg([\"min\", \"max\", \"mean\", \"median\"])\n",
    "print(schooling_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa03f9a",
   "metadata": {},
   "source": [
    "- __Pivot Tables:__ Pivot tables are the standard way of aggregating data in spreadsheets. In pandas, pivot tables are created with ```.pivot_table()``` method, and they are essentially another way of performing grouped calculations as an alternative to ```.groupby()```. The __aggfunc__ argument of ```.pivot_table()``` takes in a list of functions (without parentheses) that can be used to summarize the values. __fill_value__ replaces missing values with a substitute dummy value. __margins__ is a shortcut to pivot by two variables, while pivoting by each of those variables separately: it gives the row and column totals of the pivot table contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a976928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and Median Schooling (avg years that people aged 25+ spent in formal education) for each Region in Developing Countries:\n",
      "                                    mean    median\n",
      "                               Schooling Schooling\n",
      "Region                                            \n",
      "Africa                          4.588235      4.00\n",
      "Asia                            7.100000      7.40\n",
      "Central America and Caribbean   7.836842      7.90\n",
      "Middle East                     7.761538      8.60\n",
      "North America                   7.000000      7.00\n",
      "Oceania                         6.811111      6.50\n",
      "Rest of Europe                 10.554545     10.80\n",
      "South America                   8.150000      8.05\n"
     ]
    }
   ],
   "source": [
    "# pivot for mean and median schooling for each region in developing countries\n",
    "mean_med_schooling_by_region = developing_countries.pivot_table(values=\"Schooling\", index=\"Region\", aggfunc=[\"mean\", \"median\"])\n",
    "print(\"Mean and Median Schooling (avg years that people aged 25+ spent in formal education) for each Region in Developing Countries:\")\n",
    "print(mean_med_schooling_by_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "438bb5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schooling (avg years that people aged 25+ spent in formal education) for Developing Countries by Region and by Year:\n",
      "Year                               2003       2005       2007        All\n",
      "Region                                                                  \n",
      "Africa                         4.174510   4.358824   4.541176   4.358170\n",
      "Asia                           6.761538   6.961538   7.103846   6.942308\n",
      "Central America and Caribbean  7.384211   7.531579   7.731579   7.549123\n",
      "Middle East                    6.676923   6.938462   7.430769   7.015385\n",
      "North America                  7.100000   7.600000   8.000000   7.566667\n",
      "Oceania                        6.433333   6.577778   6.833333   6.614815\n",
      "Rest of Europe                 9.781818  10.063636  10.309091  10.051515\n",
      "South America                  7.625000   7.750000   7.800000   7.725000\n",
      "All                            6.196479   6.388028   6.593662   6.392723\n"
     ]
    }
   ],
   "source": [
    "# subset the rows where the economy status is developing for specified years\n",
    "years = [2003, 2005, 2007]\n",
    "developing_countries_by_years = world[(world[\"Economy_status_Developing\"] == 1) & (world[\"Year\"].isin(years))]\n",
    "\n",
    "# print the schooling in developing countries by region and years\n",
    "temp_dev_pivot = developing_countries_by_years.pivot_table(values=\"Schooling\", index=\"Region\", columns=\"Year\", fill_value=0, margins=True)\n",
    "print(\"Schooling (avg years that people aged 25+ spent in formal education) for Developing Countries by Region and by Year:\")\n",
    "print(temp_dev_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c302b2",
   "metadata": {},
   "source": [
    "The column 'All' returns an overall mean for each year, not (2003+2005+2007)/3. That would be a mean of means, rather than an overall mean per year! A pivot table is a DataFrame with sorted indexes, so the techniques to subset them are the same as DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19c1f679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schooling (avg years that people aged 25+ spent in formal education) for Developing Countries from Africa to Middle East, and from 2003 to 2005:\n",
      "Year                               2003      2005\n",
      "Region                                           \n",
      "Africa                         4.174510  4.358824\n",
      "Asia                           6.761538  6.961538\n",
      "Central America and Caribbean  7.384211  7.531579\n",
      "Middle East                    6.676923  6.938462\n"
     ]
    }
   ],
   "source": [
    "# print the schooling in developing countries from Africa to Middle East, and from 2003 to 2005\n",
    "print(\"Schooling (avg years that people aged 25+ spent in formal education) for Developing Countries from Africa to Middle East, and from 2003 to 2005:\")\n",
    "print(temp_dev_pivot.loc[\"Africa\":\"Middle East\", 2003:2005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d45eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-coursera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

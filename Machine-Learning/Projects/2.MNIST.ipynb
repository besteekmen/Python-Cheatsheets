{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with CNN\n",
    "\n",
    "The __MNIST__ dataset, which is available in the [tf.keras.datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) API, is a collection of grayscale 28x28 pixel handwritten digit images which is suitable for a basic classification task. The labels are returned as a number list mapping the related numbers:\n",
    "\n",
    "| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |\n",
    "\n",
    "In this project, MNIST dataset is handled with a CNN to improve the training accuracy over 99.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e773c8b370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# to get the data from a local directory, add related path to current directory\n",
    "#current_dir = os.getcwd() \n",
    "#data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
    "\n",
    "# load only the training set of the MNIST dataset\n",
    "(train_img, train_lab), _ = mnist.load_data()\n",
    "\n",
    "# pick a random image from the dataset\n",
    "i = np.random.randint(train_lab.shape[0], size=1)[0]\n",
    "\n",
    "# print image and label of the randomly selected sample\n",
    "print(\"Label:\", train_lab[i])\n",
    "#print(\"Image as NumPy array: \\n\", train_img[i])\n",
    "\n",
    "# visualize the image\n",
    "plt.imshow(train_img[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, it is essential to prepare the data to feed the neural network. Here, two transformations are applied to the data:\n",
    "\n",
    "- __Reshape:__ Commonly 3-dimensional arrays (without the batch dimension) are used to represent image data. The third dimension represents the color channels using RGB values. Hence, the data is reshaped by adding an extra dimension. Even though MNIST dataset is in black and white format, adding the third dimension is a good practice.\n",
    "\n",
    "- __Normalize:__ The pixel values are normalized between 0 and 1 by dividing every value in the array by the maximum. Normalization is essential for a speedy, more accurate and high performance training as it reduces the effects of feature scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
      "Shape of an image after reshaping: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# prepare the data by applying transformations (reshape, normalize)\n",
    "\n",
    "# reshape the images to add an extra dimension\n",
    "train_img = np.expand_dims(train_img, axis = -1)\n",
    "    \n",
    "# normalize the pixel values from (0, 255) to (0, 1)\n",
    "train_img  = train_img / 255.0\n",
    "\n",
    "print(\"Maximum pixel value after normalization:\", np.max(train_img))\n",
    "print(\"Shape of training set after reshaping:\", train_img.shape)\n",
    "print(\"Shape of an image after reshaping:\", train_img[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a callback to ensure 99.5% accuracy limit\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    # check certain condition when the current epoch ends\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        # if accuracy exists and gets higher than 0.995, stop training\n",
    "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.995:\n",
    "            print(\"\\nReached 99.5% accuracy, training is terminated.\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is created with 5 layers:\n",
    "- A Conv2D layer with 32 filters, a kernel_size of 3x3, ReLU activation function\n",
    "-  A MaxPooling2D layer with a pool_size of 2x2\n",
    "- A Flatten layer with no arguments\n",
    "- A Dense layer with 128 units and ReLU activation function\n",
    "- A Dense layer with 10 units and softmax activation function\n",
    "\n",
    "and optimized with Adam optimizer using sparse categorical crossentropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the convolutional model\n",
    "def conv_model():\n",
    "    model = tf.keras.models.Sequential([ \n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        keras.layers.MaxPooling2D(2, 2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy']) \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 69s 13ms/step - loss: 0.1409 - accuracy: 0.9577\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0480 - accuracy: 0.9856\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0312 - accuracy: 0.9906\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0191 - accuracy: 0.9936\n",
      "Epoch 5/10\n",
      "1871/1875 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9962\n",
      "Reached 99.5% accuracy, training is terminated.\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0124 - accuracy: 0.9961\n"
     ]
    }
   ],
   "source": [
    "# instantiate class to add callback while training\n",
    "callbacks = myCallback()\n",
    "\n",
    "# save the untrained model\n",
    "model = conv_model()\n",
    "\n",
    "# train the model\n",
    "history = model.fit(train_img, train_lab, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5408)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               692352    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "The model was trained for 5 epochs\n"
     ]
    }
   ],
   "source": [
    "# print the model summary\n",
    "model.summary()\n",
    "\n",
    "# check the training history\n",
    "print(\"The model was trained for\", len(history.epoch), \"epochs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-coursera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
